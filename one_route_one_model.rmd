---
title: "one_route_one_model"
author: "Members"
date: '2023-02-08'
output: pdf_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)
library(stargazer)
set.seed(12)
```


Initial data cleaning:

```{r, cache=TRUE}
# get the data
# Temperature Data
temp_data <- 
  read.table("data/temperature-data.txt", 
           skip = 1, 
           col.names = c('time1', 'time2', 'daily_max', 'daily_min')) %>% 
  mutate(year = as.numeric(substring(time2, 1, 4))) %>% 
  mutate(month = as.numeric(substring(time2, 6, 7))) %>% 
  mutate(day = as.numeric(substring(time2, 9, 10))) %>%
  mutate(daily_temp = (daily_max + daily_min) / 2)
# Remove outliers with IQR range test
outliers <- function(x) {
    q25 <- quantile(x, probs=.25)
    q75 <- quantile(x, probs=.75)
    interval <- q75 - q25
    x > q75 + (interval * 1.5) | x < q25 - (interval * 1.5)
}
# Bike-share Data
load("data/bikedata.RData")
colnames(starttime) = c("year", "month", "day", "hour", "minute", "second")
df <- data.frame(log_duration = log(duration), station_start, station_end, 
                starttime, day_of_week, days_since_Jan1_2010, member) %>% 
  # Join with Temperature Data
  left_join(temp_data, by = c('year','month','day')) %>% 
  # Add Weekend/weekday 
  mutate(weekend = day_of_week %in% c("Saturday", "Sunday")) %>% 
  # Add Hour of the Day
  mutate(hour_of_day = cut(hour, c(-1, 6, 12, 18, 24))) %>%
  # Add temperature buckets
  mutate(temp = cut(daily_temp, c(20, 40, 60, 80, 100))) %>%
  # Assign Id to Route
  group_by(station_start, station_end) %>% 
  mutate(route = paste0(station_start, "-", station_end)) %>% 
  mutate(route = factor(route)) %>% 
  # Filter out routes with less than 500 records
  filter(length(log_duration) >= 500 & !outliers(log_duration)) %>% 
  ungroup()
# drop 2011 Jan-Aug data
df <- df %>% filter(month %in% 9:12) %>% 
  mutate(month = factor(month)) %>% 
  mutate(day_of_week = factor(day_of_week)) %>% 
  mutate(day_of_week = fct_relevel(day_of_week, c("Monday","Tuesday","Wednesday",
                                                  "Thursday","Friday","Saturday","Sunday"))) %>% 
  mutate(hour = factor(hour))
```


We want to make sure for each route we train a model on, there is enough data. Since we use 2011 data to build the regression model, we filter for "busy" routes based on 2011's data. Here, we decide to only consider the routes with more than 100 rides during September - December in 2011.

We also filter for routes that have more than 100 routes in 2010.


```{r cache=TRUE}
busy_routes_df_2011 <- df %>% 
  filter(year==2011) %>% 
  group_by(route) %>% 
  summarise(ride_counts = n()) %>% 
  filter(ride_counts >= 100)

busy_routes_2011 <- busy_routes_df_2011$route


busy_routes_df_2010 <- df %>% 
  filter(year==2010) %>% 
  group_by(route) %>% 
  summarise(ride_counts = n()) %>% 
  filter(ride_counts >= 100)

busy_routes_2010 <- busy_routes_df_2010$route
# we only want to make predictions for routes that have enough
# rides in both years
busy_routes <- intersect(busy_routes_2011, busy_routes_2010)
```


```{r}
# split data by year
df11 <- df %>% filter(year == 2011 & route %in% busy_routes) %>% 
  select(c(log_duration, member, year, month, day, hour, day_of_week, daily_temp, weekend, route))

df10 <- df %>% filter(year == 2010 & route %in% busy_routes)
```

Regression formula:

log_duration ~ member + month + day_of_week + factor(hour) + weekend + daily_temp + route


```{r}
p_vals = c()
```


```{r}
for (a_route in busy_routes) {
  # pick a route and give it a try
  #a_route = '31101-31200'
  
  # filter for this route's data
  route_df11 <- df11 %>% filter(route == a_route)
  route_df10 <- df10 %>% filter(route == a_route)
  
  # create hold-out set for 2011 data
  picked = sample(seq_len(nrow(route_df11)), size = nrow(route_df11)*0.7)
  df11_train =route_df11[picked,]
  df11_holdout =route_df11[-picked,]
  
  # train a model for this route
  # print(a_route)
  lm_2011 = lm(log_duration ~ member + daily_temp + month + day_of_week + hour, data = df11_train)
  #summary(lm_2011)
  
  # aggregate on 2011 hold-out set
  df11_holdout_agg <- df11_holdout %>% 
    select(-c(year, weekend)) %>% 
    group_by(month, day, hour, member) %>% 
    mutate(log_duration = median(log_duration)) %>% 
    mutate(counts = n()) %>% 
    ungroup() %>% 
    distinct() %>% 
    arrange(month, day, hour, member)
  
  # make sure that the hold-out set doesn't have new levels
  df11_holdout_agg <- df11_holdout_agg %>% 
    filter(hour %in% unique(df11_train$hour)) %>% 
    filter(day_of_week %in% unique(df11_train$day_of_week))
  
  # make predictions for the hold-out set
  prediction_2011_holdout <- data.frame(predict(lm_2011, newdata = df11_holdout_agg, 
                                     interval = "predict", level = 0.95, 
                                     weights = df11_holdout_agg$counts)) %>% 
    mutate(true_duration = df11_holdout_agg$log_duration)
  
  # find non-coverage rate on hold-out set
  holdout_noncover = nrow(prediction_2011_holdout %>% filter(true_duration>upr | true_duration<lwr))
  holdout_total = nrow(prediction_2011_holdout)
  holdout_noncover_rate = holdout_noncover/holdout_total
  
  # aggregate on 2010 test data
  df10_agg <- route_df10 %>% 
    select(-c(year, weekend)) %>% 
    group_by(month, day, hour, member) %>% 
    mutate(log_duration = median(log_duration)) %>% 
    mutate(counts = n()) %>% 
    ungroup() %>% 
    distinct() %>% 
    arrange(month, day, hour, member)
  
  # make sure that the 2010 test set doesn't have new levels
  df10_agg <- df10_agg %>% 
    filter(hour %in% unique(df11_train$hour)) %>% 
    filter(day_of_week %in% unique(df11_train$day_of_week))
  
  # make predictions on 2010 test set
  prediction_2010 <- data.frame(predict(lm_2011, newdata = df10_agg, 
                                     interval = "predict", level = 0.95, weights = df10_agg$counts)) %>% 
    mutate(true_duration = df10_agg$log_duration) 
  
  # find non-coverage rate on test set
  test_noncover = nrow(prediction_2010 %>% filter(true_duration>upr | true_duration<lwr)) 
  test_total = nrow(prediction_2010)
  test_noncover_rate = test_noncover / test_total
  
  # do binomial test on the 2 non-coverage rates; find p value
  res = binom.test(test_noncover,
               test_total,
               holdout_noncover_rate,
               alternative = "greater")
  p_val = res$p.value
  p_vals = append(p_vals, p_val)
}
```

```{r}
p_vals = p.adjust(p_vals, method = 'fdr')
final = data.frame(busy_routes, p_vals)
final = final %>% filter(p_vals < 0.05)
final
```


```{r}
write.csv(final,file='one_model_per_route.csv')
```


























