---
title: "Regression -- A Prediction-Based Approach"
output: pdf_document
---


```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)
library(stargazer)
set.seed(12)
theme_set(theme_bw())
```

# Section I: Introduction to the Regression Approach

The gist of this approach is using one year's data to predict the other year's ride durations (the outcome variable), and then comparing the predictions to the actual durations. The intuition is that if there is no significant change in the routes, we should expect to see that the predictions and the true ride durations to be close to each other. And if we observe a statistically significant amount of differences between them for a certain route, this could be a potential evidence that this route had changed between 2010 and 2011.

Before delving into the details of each step of this approach, we want to acknowledge some limitations of this approach in answering the original question of "detecting if there is any change at any point for each route". This approach, as an exploratory analysis, simplifies the question asked. Instead, here we are investigating if there is a change between 2010 and 2011 for each route. Furthermore, due to the limitation of the data (and the fact that this bike share program in D.C. only started in late 2010), we are only comparing Sept.-Dec. 2010 vs. Sept.-Dec. 2011, as there is no data in 2010 from Jan. to Aug. 

Again, since the program started in late 2010, there was less data in 2010 than in 2011. Thus, in order to consider more routes in our regression model (a route needs to have enough data to be included in the model; otherwise there can be too much noise), we decided to use 2011 Sept.-Dec.'s data to train the model, and then apply the model on 2010's data for testing.

## 1.1 Outline of the steps taken

**Step 0:** Data cleaning. Details will be discussed in the later section.

**Step 1:** Filter for 2011 Sept.-Dec.'s data. Create a hold-out set for 2011 (for example, 20%). This hold-out set (validation set) will be used to compare with the prediction performance of the model on the test set later.

**Step 2:** Train a regression model using 2011’s training data. Here, we tried two approaches when training the model. 

One approach is to train one single model for all the routes, with `route` as a covariate in the model. This will assume that covariates, such as day of week, daily temperature, membership status etc., have the same effects on ride duration across all the routes. While we believe this might be generally true, there definitely can be instances where, for example, some covariate like a low daily temperature (cold weather) has a greater effect on ride duration because of the terrain or geography of some route. i.e. there can be interactions between `route` and other covariates. But we are not including them in the model due to the limitation of sample size.

Another approach is to train a different model for each route we consider. While this may better account for the interaction between `route` and other covariates, since we generally only have hundreds of data points for each route, the relatively low sample size may make the models less robust. 

In the later sections, we implemented both approaches.

**Step 3:** Aggregate the hold-out data set by categorical covariates. Since the data is assumed to be noisy, we decided to aggregate each route’s data on an hourly basis (and control for membership status) by taking median for the ride duration. We record how many original samples each aggregated sample represents, and this will be used as weights when making predictions.

*Note:* We didn't aggregate the data when building the model to allow for a wider range for the feature values, so that it's less likely for extrapolation to happend when making predictions.

**Step 4:** Apply the model on the 2011 hold-out set. Construct 95% prediction intervals for the hold-out data set, adjusted for the weights mentioned in step 3. Record the non-coverage rate of the prediction intervals for each route.

**Step 5:** Apply the regression model on the aggregated 2010 data set. Construct prediction intervals and find a new non-coverage rate for each route. Perform a binomial test on the the non-coverage rates we get when applying the model on the 2011 validation set and the 2010 test set.

**Step 6:** Adjust the p-values from the tests for the multiple testing issue, and then report the routes with significant change in non-coverage rate, i.e. the routes that have statistically significant change between 2010 and 2011.

## 1.2 Initial data cleaning

We get additional data on daily average temperature in Washington D.C. from North America Land Data Assimilation System. We take a log transformation on ride duration to make it less skewed. Then, we remove outliers in `log_duration` using the 1.5 IQR rule and remove routes with less than 500 rides in the original data set to make out test to be less affected by the outliers. In the end, we exclude the data from Jan. to Aug. in 2011, as discussed earlier in the outline.

```{r, cache=TRUE}
# Temperature Data
temp_data <- 
  read.table("data/temperature-data.txt", 
           skip = 1, 
           col.names = c('time1', 'time2', 'daily_max', 'daily_min')) %>% 
  mutate(year = as.numeric(substring(time2, 1, 4))) %>% 
  mutate(month = as.numeric(substring(time2, 6, 7))) %>% 
  mutate(day = as.numeric(substring(time2, 9, 10))) %>%
  mutate(daily_temp = (daily_max + daily_min) / 2)

# Remove outliers with IQR range test
outliers <- function(x) {
    q25 <- quantile(x, probs=.25)
    q75 <- quantile(x, probs=.75)
    interval <- q75 - q25
    x > q75 + (interval * 1.5) | x < q25 - (interval * 1.5)
}

# Bike-share Data
load("data/bikedata.RData")
colnames(starttime) = c("year", "month", "day", "hour", "minute", "second")
df <- data.frame(log_duration = log(duration), station_start, station_end, 
                starttime, day_of_week, days_since_Jan1_2010, member) %>% 
  # Join with Temperature Data
  left_join(temp_data, by = c('year','month','day')) %>% 
  # Add Weekend/weekday 
  mutate(weekend = day_of_week %in% c("Saturday", "Sunday")) %>% 
  # Add Hour of the Day
  mutate(hour_of_day = cut(hour, c(-1, 6, 12, 18, 24))) %>%
  # Add temperature buckets
  mutate(temp = cut(daily_temp, c(20, 40, 60, 80, 100))) %>%
  # Assign Id to Route
  group_by(station_start, station_end) %>% 
  mutate(route = paste0(station_start, "-", station_end)) %>% 
  mutate(route = factor(route)) %>% 
  # Filter out routes with less than 500 records
  filter(length(log_duration) >= 500 & !outliers(log_duration)) %>% 
  ungroup()
# drop 2011 Jan-Aug data
df <- df %>% filter(month %in% 9:12) %>% 
  mutate(month = factor(month)) %>% 
  mutate(day_of_week = factor(day_of_week)) %>% 
  mutate(day_of_week = fct_relevel(day_of_week, c("Monday","Tuesday","Wednesday",
                                                  "Thursday","Friday","Saturday","Sunday"))) %>% 
  mutate(hour = factor(hour))
```


# Section II: One Single Model for All Routes, with `route` as a Covariate

In this section, we implemented the test using one single regression model for all routes, with `route` as a covariate.

We want to make sure for each route we train the model on, there is enough data. Since we use 2011 data to build the regression model, we filter for "busy" routes based on 2011's data. Here, we decide to only consider the routes with more than 100 rides during September - December in 2011.

We also filter for routes that have more than 100 routes in 2010. A route with too few rides in the test set can result in too much variation in the non-coverage rate, so we decide to only apply the regression model for routes with enough rides when making predictions.

```{r cache=TRUE}
busy_routes_df <- df %>% 
  filter(year==2011) %>% 
  group_by(route) %>% 
  summarise(ride_counts = n()) %>% 
  filter(ride_counts >= 100)
busy_routes <- busy_routes_df$route

busy_routes_df_2010 <- df %>% 
  filter(year==2010) %>% 
  group_by(route) %>% 
  summarise(ride_counts = n()) %>% 
  filter(ride_counts >= 100)
busy_routes_2010 <- busy_routes_df_2010$route
busy_routes_2010 <- intersect(busy_routes, busy_routes_2010)

# split data by year
df11 <- df %>% filter(year == 2011 & route %in% busy_routes) %>% 
  select(c(log_duration, member, year, month, day, hour, 
           day_of_week, daily_temp, weekend, route))

df10 <- df %>% filter(year == 2010 & route %in% busy_routes_2010)
```
\ 

## 2.1 Implementation of the Test

\ 

### Step 1: create a hold-out set for 2011

Here, we use 80% of 2011's data to train the model. The rest of 20% will be validation set.

```{r cache=TRUE}
# create hold-out set for 2011
picked = sample(seq_len(nrow(df11)), size = nrow(df11)*0.8)
df11_train =df11[picked,]
df11_holdout =df11[-picked,]
```
\ 

### Step 2: train a regression model using 2011’s training data

Regression formula:

`log_duration` ~ `member` + `month` + `day_of_week` + `factor(hour)` + `daily_temp` + `route`

We regress `log_duration` on membership status, month, day of week, hour, and daily temperature. Additionally, `route` is also included as a covariate in the model.

```{r cache=TRUE}
lm_2011 = lm(log_duration ~ member + daily_temp + month + day_of_week + hour + route, 
             data = df11_train)
```

```{r echo = F, results = 'hide'}
summary(lm_2011)
```
\ 

### Step 3: aggregation on 2011 hold-out set

We perform aggregation on the 2011 hold-out data set by grouping rides for each route from the same hour and membership status together. We do the aggregation by taking the median on `log_duration`. Aggregation supposedly should make the data less noisy. We also keep track of the number of samples represented by each row in this aggregated data frame. This will be used as weights when we construct the prediction intervals in the next step.

```{r cache=TRUE}
df11_holdout_agg <- df11_holdout %>% 
  select(-c(year, weekend)) %>% 
  group_by(route, month, day, hour, member) %>% 
  mutate(log_duration = median(log_duration)) %>% 
  mutate(counts = n()) %>% 
  ungroup() %>% 
  distinct() %>% 
  arrange(route, month, day, hour, member)
```
\ 

### Step 4: construct prediction intervals for the hold-out data set

Here, we just want to make sure that there is no route that only appears in the hold-out set, but not in the training set, as this will make the `predict()` function fail. After checking this, we know it didn't happen. 

```{r cache=TRUE}
train_routes <- unique(df11_train$route)
df11_holdout_agg <- df11_holdout_agg %>% 
  filter(route %in% train_routes)
```

Then, we make predictions for the 2011 hold-out set, and construct 95% prediction intervals adjusted by weights.

Without aggregation, the formula for the prediction interval of a new sample is: 
$$\hat{y}_h \pm t_{(1-\alpha/2, n-2)} \times \sqrt{MSE \times \left(1+ \frac{1}{n} + \dfrac{(x_h-\bar{x})^2}{\sum(x_i-\bar{x})^2}\right)}$$

Now, for an aggregated sample $i$ with weight $w_i$, where $w_i$ represents the number of original samples being aggregated into this aggregated sample, the formula for the prediction interval of a new aggregated sample is:
$$\hat{y}_h \pm t_{(1-\alpha/2, n-2)} \times \sqrt{MSE \times \left(\frac{1}{\sqrt{w_i}}+ \frac{1}{n} + \dfrac{(x_h-\bar{x})^2}{\sum(x_i-\bar{x})^2}\right)}$$


```{r cache=TRUE}
prediction_2011_holdout <- data.frame(predict(lm_2011, newdata = df11_holdout_agg, 
                                   interval = "predict", level = 0.95, 
                                   weights = df11_holdout_agg$counts)) %>% 
  mutate(true_duration = df11_holdout_agg$log_duration)
```

The 95% prediction intervals for the hold-out set as a whole have a non-coverage rate of 0.04799874, which is roughly equal to what we expect (0.05):

```{r}
overall_nc_rate_2011 <- nrow(prediction_2011_holdout %>% 
       filter(true_duration>upr | true_duration<lwr)) / nrow(prediction_2011_holdout)
overall_nc_rate_2011
```
\ 

Then, we compute the non-coverage rates each route in the 2011 hold-out set. The non-coverage rate for route $i$ is defined as: $$ \frac{number \ of \ rides \ of \ route \ i \ whose \ true \ duration \ lies \ outside \ of \ the \ prediction \ interval}{total \ number \ of \ rides \ of \ route \ i}$$
```{r}
noncoverage_rates_2011 <- prediction_2011_holdout %>% 
  mutate(route = df11_holdout_agg$route) %>% 
  group_by(route) %>% 
  mutate(total_ride_count = n()) %>% 
  mutate(noncoverage_count = sum(true_duration>upr | true_duration<lwr)) %>% 
  mutate(noncoverage_proportion = noncoverage_count / total_ride_count) %>% 
  ungroup() %>% 
  select(c(route, total_ride_count, noncoverage_count, noncoverage_proportion)) %>% 
  distinct() %>% 
  arrange(desc(noncoverage_proportion)) %>% 
  filter(route %in% busy_routes_2010)
```


Now, if the 2010's data doesn't have significant change from 2011's data, we should also expect to see a non-coverage rate of roughly 5%. 

\ 

### Step 5: apply the regression model on the aggregated 2010 data set, construct prediction intervals, find non-coverage rate for each route, and then perform binomial tests to see if the non-coverage rate on the testing set is significantly greater than that on the hold-out set

Again, we first aggregate 2010's data by hour and by membership status and compute weights, just like what we did to 2011's hold-out set:

```{r}
df10_agg <- df10 %>% 
  select(-c(year, weekend)) %>% 
  group_by(route, month, day, hour, member) %>% 
  mutate(log_duration = median(log_duration)) %>% 
  mutate(counts = n()) %>% 
  ungroup() %>% 
  distinct() %>% 
  filter(route %in% train_routes) %>% 
  arrange(route, month, day, hour, member)
```

Then, we create prediction intervals, adjusted by weights:

```{r cache=TRUE}
prediction_2010 <- data.frame(predict(lm_2011, newdata = df10_agg, 
                                   interval = "predict", level = 0.95, 
                                   weights = df10_agg$counts)) %>% 
  mutate(true_duration = df10_agg$log_duration) %>% 
  mutate(route = df10_agg$route)
```


Finally, we get an overall non-coverage rate of 0.1022566, which is greater than 0.05. 

```{r}
nrow(prediction_2010 %>% 
       filter(true_duration>upr | true_duration<lwr)) / nrow(prediction_2010)
```

We can do a binomial test to see if the overall non-coverage rate of the 2010 test set is significantly greater than the overall non-coverage rate of the 2011 hold-out set:

```{r}
binom.test(nrow(prediction_2010 %>% filter(true_duration>upr | true_duration<lwr)),
           nrow(prediction_2010),
           overall_nc_rate_2011)$p.value
```

This small p-value indicates that there was some route that had changed between 2010 and 2011. Next, we test for each route whether it had significant change or not.

We first compute the non-coverage rates for the routes in the 2010 testing set:

```{r}
noncoverage_rates_2010 <- prediction_2010 %>% 
  group_by(route) %>% 
  mutate(total_ride_count = n()) %>% 
  mutate(noncoverage_count = sum(true_duration>upr | true_duration<lwr)) %>% 
  mutate(noncoverage_proportion = noncoverage_count / total_ride_count) %>% 
  ungroup() %>% 
  select(c(route, total_ride_count, noncoverage_count, noncoverage_proportion)) %>% 
  distinct() %>% 
  arrange(desc(noncoverage_proportion))
```

The for each `busy_route`, i.e. each route that had more than 100 rides in both 2010 Sept-Dec and 2011 Sept-Dec, we do a binomial test to see if its non-coverage rates on 2011 hold-out set and 2010 testing set are significantly different than each other:

```{r message=FALSE, warning=FALSE, cache=TRUE}
p_vals = c()

for (a_route in busy_routes_2010) {

  route_info_2011 = noncoverage_rates_2011 %>% filter(`route` == a_route)
  route_info_2010 = noncoverage_rates_2010 %>% filter(`route` == a_route)
  
  noncov_rate_2011 = route_info_2011$noncoverage_proportion
  
  num_noncoverage_2010 = route_info_2010$noncoverage_count
  total_2010 = route_info_2010$total_ride_count 
  
  res = binom.test(num_noncoverage_2010,
             total_2010,
             noncov_rate_2011,
             alternative = "greater")
  
  p_val = res$p.value
  p_vals = append(p_vals, p_val)
}
```

\ 

### Step 6: Adjust the p-values for multiple testing issue and report the routes with significant change in non-coverage rate, i.e. the routes that have statistically significant change between 2010 and 2011

```{r}
p_vals = p.adjust(p_vals, method = 'fdr')
final1 = data.frame(noncoverage_rates_2010$route, p_vals)
final1 = final1 %>% filter(p_vals < 0.05)
length(final1$noncoverage_rates_2010.route)
```

After adjusting for multiple testing issue, we report 76 significant routes out of 159 `busy_routes` we considered. 

Is this result reliable? In the next subsection, we further discuss one potential limitation of this regression prediction-based approach.

## 2.2 Discussion

One potential limitation of the result above is that, there is a possibility that the composition of the riders of a route (especially for covariates that we could not control for, such as age) changed between 2010 and 2011, which resulted in the change in the ride duration. While we are not able to see if the unobserved confounders did have significant change, we may take a look at the observed covariates and see their distribution in both years, which could give us some evidence of whether this potential limitation has a significant impact or not.

First, we take a look at the overall composition of the covariates of both years.

(i) 2010 and 2011 member vs non-member
```{r echo=FALSE, fig.align='center', fig.height=2.2, fig.width=4, cache=TRUE}
# Group 2010 and 2011 data by membership
df_10_member <- df10 %>%
  group_by(member) %>%
  summarize(frequency = n() / nrow(df10))

df_11_member <- df11 %>%
  group_by(member) %>%
  summarize(frequency = n() / nrow(df11))

# Combine the grouped data into a single data frame
df_combined <- rbind(df_10_member, df_11_member)
df_combined$data_frame <- c(rep("membership, 2010", 2), rep("membership, 2011", 2))

# Create the bar plot
ggplot(df_combined, aes(x = member, y = frequency, fill = member)) +
  geom_bar(stat = "identity", position = "dodge", show.legend = FALSE) +
  facet_wrap(~ data_frame, scales = "free", ncol = 2) +
  labs(x = "Membership status", y = "Frequency", fill = "Membership status",
       caption = "Figure 1") +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0))
```

(ii) 2010 and 2011 day of week
```{r echo=FALSE, fig.align='center', fig.height=2.5, fig.width=5.5, cache=TRUE}
# Group 2010 and 2011 data by day of week
df_10_weekdays <- df10 %>%
  group_by(day_of_week) %>%
  summarize(frequency = n() / nrow(df10)) %>% 
  mutate(day_of_week = recode_factor(day_of_week,"Monday"="Mon","Tuesday"="Tues",
                                     "Wednesday"="Wed","Thursday"="Thurs",
                                     "Friday"="Fri","Saturday"="Sat","Sunday"="Sun"))

df_11_weekdays <- df11 %>%
  group_by(day_of_week) %>%
  summarize(frequency = n() / nrow(df11)) %>% 
  mutate(day_of_week = recode_factor(day_of_week,"Monday"="Mon","Tuesday"="Tue",
                                     "Wednesday"="Wed","Thursday"="Thur",
                                     "Friday"="Fri","Saturday"="Sat","Sunday"="Sun"))

# Combine the grouped data into a single data frame
df_combined <- rbind(df_10_weekdays, df_11_weekdays)
df_combined$data_frame <- c(rep("day of week, 2010", 7), rep("day of week, 2011", 7))

# Create the bar plot
ggplot(df_combined, aes(x = day_of_week, y = frequency)) +
  geom_bar(stat = "identity", position = "dodge", fill = "steelblue3") +
  facet_wrap(~ data_frame, scales = "free", ncol = 2) +
  labs(x = "Day of week", y = "Frequency", 
       caption = "Figure 2") 
```

(iii) 2010 and 2011 hour of day
```{r echo=FALSE, fig.align='center', fig.height=2.5, fig.width=5.5, cache=TRUE}
# Group 2010 and 2011 data by hour of day
df_10_hour <- df10 %>%
  group_by(hour_of_day) %>%
  summarize(frequency = n() / nrow(df10))

df11 <- df %>% filter(year == 2011 & route %in% busy_routes) 
df_11_hour <- df11 %>%
  group_by(hour_of_day) %>%
  summarize(frequency = n() / nrow(df11))

# Combine the grouped data into a single data frame
df_combined <- rbind(df_10_hour, df_11_hour)
df_combined$data_frame <- c(rep("hour of day, 2010", 4), rep("hour of day, 2011", 4))

# Create the bar plot
ggplot(df_combined, aes(x = hour_of_day, y = frequency)) +
  geom_bar(stat = "identity", position = "dodge", fill = "steelblue3") +
  facet_wrap(~ data_frame, scales = "free", ncol = 2) +
  labs(x = "Hour of day", y = "Frequency",
       caption = "Figure 3") 
```

Using the above three plots, we visually inspect and compare the overall distributions of membership, day of week, and hour of day in 2010 and 2011. While there is a little perturbation in the distribution of hour of day, in general we didn't see significant changes in the composition of the observed covariates.

Next, we examine a randomly selected route's composition of the same set of covariates in 2010 and 2011, to see if this still holds on the route-level. 

(i) 2010 and 2011 member vs non-member -- route `31202-31214`

```{r echo=FALSE, fig.align='center', fig.height=2.2, fig.width=4}
# Group 2010 and 2011 data by membership
df_10_member <- df10 %>% filter(route=='31202-31214') %>% 
  group_by(member) %>%
  summarize(n = n()) %>% 
  mutate(frequency = n/sum(n))

df_11_member <- df11 %>% filter(route=='31202-31214') %>% 
  group_by(member) %>%
  summarize(n = n()) %>% 
  mutate(frequency = n/sum(n))

# Combine the grouped data into a single data frame
df_combined <- rbind(df_10_member, df_11_member)
df_combined$data_frame <- c(rep("membership, 2010", 2), rep("membership, 2011", 2))

# Create the bar plot
ggplot(df_combined, aes(x = member, y = frequency, fill = member)) +
  geom_bar(stat = "identity", position = "dodge", show.legend = FALSE) +
  facet_wrap(~ data_frame, scales = "free", ncol = 2) +
  labs(x = "Membership status", y = "Frequency", fill = "Membership status",
       caption = "Figure 4") +
  scale_y_continuous(limits = c(0, 1), expand = c(0, 0))
```

(ii) 2010 and 2011 day of week -- route `31202-31214`

```{r echo=FALSE, fig.align='center', fig.height=2.5, fig.width=5.5}
# Group 2010 and 2011 data by day of week
df_10_weekdays <- df10 %>% filter(route=='31202-31214') %>% 
  group_by(day_of_week) %>%
  summarize(n = n()) %>% 
  mutate(frequency = n/sum(n)) %>% 
  mutate(day_of_week = recode_factor(day_of_week,"Monday"="Mon","Tuesday"="Tue",
                                     "Wednesday"="Wed","Thursday"="Thur",
                                     "Friday"="Fri","Saturday"="Sat","Sunday"="Sun"))

df_11_weekdays <- df11 %>% filter(route=='31202-31214') %>% 
  group_by(day_of_week) %>%
  summarize(n = n()) %>% 
  mutate(frequency = n/sum(n)) %>% 
  mutate(day_of_week = recode_factor(day_of_week,"Monday"="Mon","Tuesday"="Tues",
                                     "Wednesday"="Wed","Thursday"="Thurs",
                                     "Friday"="Fri","Saturday"="Sat","Sunday"="Sun"))

# Combine the grouped data into a single data frame
df_combined <- rbind(df_10_weekdays, df_11_weekdays)
df_combined$data_frame <- c(rep("day of week, 2010", 7), rep("day of week, 2011", 7))

# Create the bar plot
ggplot(df_combined, aes(x = day_of_week, y = frequency)) +
  geom_bar(stat = "identity", position = "dodge", fill = "steelblue3") +
  facet_wrap(~ data_frame, scales = "free", ncol = 2) +
  labs(x = "Day of week", y = "Frequency", 
       caption = "Figure 5") 
```

(iii) 2010 and 2011 hour of day -- route `31202-31214`

```{r echo=FALSE, fig.align='center', fig.height=2.5, fig.width=5.5}
# Group 2010 and 2011 data by hour of day
df_10_hour <- df10 %>% filter(route=='31202-31214') %>% 
  group_by(hour_of_day) %>%
  summarize(n = n()) %>% 
  mutate(frequency = n/sum(n)) 

df11 <- df %>% filter(year == 2011 & route %in% busy_routes) 
df_11_hour <- df11 %>% filter(route=='31202-31214') %>% 
  group_by(hour_of_day) %>%
  summarize(n = n()) %>% 
  mutate(frequency = n/sum(n)) 

# Combine the grouped data into a single data frame
df_combined <- rbind(df_10_hour, df_11_hour)
df_combined$data_frame <- c(rep("hour of day, 2010", 4), rep("hour of day, 2011", 4))

# Create the bar plot
ggplot(df_combined, aes(x = hour_of_day, y = frequency)) +
  geom_bar(stat = "identity", position = "dodge", fill = "steelblue3") +
  facet_wrap(~ data_frame, scales = "free", ncol = 2) +
  labs(x = "Hour of day", y = "Frequency", 
       caption = "Figure 6") 
```


However, when we examine the above plots generated from a randomly selected significant route we identified, there is indeed more variations in the observed covariates between 2010 and 2011. While we controlled for these observed covariates, this suggests that the composition of other unobserved confounders such as age might also change, which can cause the change in the non-coverge rates we found.

Because of the limitation of the data set, we are not able to control for variables such as age, and we can only assume that the composition of the unobserved confounders doesn't change for each route across 2010 and 2011. 

Ideally, we could have better control for the effect of the potential change in the composition of the unobserved confounders between 2010 and 2011 by more carefully select the testing set. Instead of using all the 2010 data as the testing set, we may try to find the samples that are "similar" (in terms of the covariates' values) to the samples in the hold-out set. Supposedly, unobserved confounders are more likely to be the same if the observed covariates are the same or at least similar. In this way, we may reduce the effect of the potential change in the composition of the unobserved confounders between 2010 and 2011.

\ 

# Section III: Different model for different routes

```{r include=FALSE}
rm(list=ls())
```


```{r include=FALSE}
library(tidyverse)
library(ggplot2)
library(stargazer)
set.seed(12)
```

Now we consider the second way of constructing the regression model. That is, instead of letting all the routes share the same coefficients, we construct a separate regression model for each route. Then, we follow the same procedure used in section II to test for the difference in the non-coverage rates on the hold-out set and test set we get when we use the model to construct prediction intervals.

## 3.1 Implementation of the Test


```{r cache=TRUE, include=FALSE}
# get the data
# Temperature Data
temp_data <- 
  read.table("data/temperature-data.txt", 
           skip = 1, 
           col.names = c('time1', 'time2', 'daily_max', 'daily_min')) %>% 
  mutate(year = as.numeric(substring(time2, 1, 4))) %>% 
  mutate(month = as.numeric(substring(time2, 6, 7))) %>% 
  mutate(day = as.numeric(substring(time2, 9, 10))) %>%
  mutate(daily_temp = (daily_max + daily_min) / 2)
# Remove outliers with IQR range test
outliers <- function(x) {
    q25 <- quantile(x, probs=.25)
    q75 <- quantile(x, probs=.75)
    interval <- q75 - q25
    x > q75 + (interval * 1.5) | x < q25 - (interval * 1.5)
}
# Bike-share Data
load("data/bikedata.RData")
colnames(starttime) = c("year", "month", "day", "hour", "minute", "second")
df <- data.frame(log_duration = log(duration), station_start, station_end, 
                starttime, day_of_week, days_since_Jan1_2010, member) %>% 
  # Join with Temperature Data
  left_join(temp_data, by = c('year','month','day')) %>% 
  # Add Weekend/weekday 
  mutate(weekend = day_of_week %in% c("Saturday", "Sunday")) %>% 
  # Add Hour of the Day
  mutate(hour_of_day = cut(hour, c(-1, 6, 12, 18, 24))) %>%
  # Add temperature buckets
  mutate(temp = cut(daily_temp, c(20, 40, 60, 80, 100))) %>%
  # Assign Id to Route
  group_by(station_start, station_end) %>% 
  mutate(route = paste0(station_start, "-", station_end)) %>% 
  mutate(route = factor(route)) %>% 
  # Filter out routes with less than 500 records
  filter(length(log_duration) >= 500 & !outliers(log_duration)) %>% 
  ungroup()
# drop 2011 Jan-Aug data
df <- df %>% filter(month %in% 9:12) %>% 
  mutate(month = factor(month)) %>% 
  mutate(day_of_week = factor(day_of_week)) %>% 
  mutate(day_of_week = fct_relevel(day_of_week, 
                                   c("Monday","Tuesday","Wednesday",
                                     "Thursday","Friday","Saturday","Sunday"))) %>% 
  mutate(hour = factor(hour))
```


We perform the same initial data cleaning as in section II, and again we want to make sure for each route we train a model on, there is enough data. That is, we are only considering routes with more than 100 rides in both 2010 Sept-Dec and 2011 Sept-Dec:


```{r cache=TRUE}
busy_routes_df_2011 <- df %>% 
  filter(year==2011) %>% 
  group_by(route) %>% 
  summarise(ride_counts = n()) %>% 
  filter(ride_counts >= 100)

busy_routes_2011 <- busy_routes_df_2011$route


busy_routes_df_2010 <- df %>% 
  filter(year==2010) %>% 
  group_by(route) %>% 
  summarise(ride_counts = n()) %>% 
  filter(ride_counts >= 100)

busy_routes_2010 <- busy_routes_df_2010$route
# we only want to make predictions for routes that have enough
# rides in both years
busy_routes <- intersect(busy_routes_2011, busy_routes_2010)

# split data by year
df11 <- df %>% filter(year == 2011 & route %in% busy_routes) %>% 
  select(c(log_duration, member, year, month, day, hour, 
           day_of_week, daily_temp, weekend, route))

df10 <- df %>% filter(year == 2010 & route %in% busy_routes)
```

Then, we iterate through the `busy_routes`. For each iteration, we filter for data of the route we are currently considering. Then, follow the same steps in the outline. That is, we

(1) randomly split the 2011 data set into a training set and a hold-out/validation set; 

(2) train a model using the training set. In this case `route` is not a covariate anymore (i.e. the regression formula in this case is `log_duration` ~ `member` + `month` + `day_of_week` + `factor(hour)` + `daily_temp`);

(3) aggregate the hold-out set;

(4) apply the model onto the aggregated hold-out set, construct weighted prediction intervals, find non-coverage rate of the prediction intervals on the hold-out set;

(5) apply the model onto the aggregated testing set, construct weighted prediction intervals, find non-coverage rate of the prediction intervals on the testing set;

(6) perform a binomial test on the difference between the two non-coverage rates and get a p-value.

After all the iterations, we adjust the p-values for multiple testing issues. 


```{r}
p_vals = c()
```


```{r cache=TRUE, message=FALSE, warning=FALSE}
for (a_route in busy_routes) {
  
  # filter for this route's data
  route_df11 <- df11 %>% filter(route == a_route)
  route_df10 <- df10 %>% filter(route == a_route)
  
  # create hold-out set for 2011 data
  picked = sample(seq_len(nrow(route_df11)), size = nrow(route_df11)*0.7)
  df11_train =route_df11[picked,]
  df11_holdout =route_df11[-picked,]
  
  # train a model for this route
  # print(a_route)
  lm_2011 = lm(log_duration ~ member + daily_temp + month + day_of_week + hour, 
               data = df11_train)
  
  # aggregate on 2011 hold-out set
  df11_holdout_agg <- df11_holdout %>% 
    select(-c(year, weekend)) %>% 
    group_by(month, day, hour, member) %>% 
    mutate(log_duration = median(log_duration)) %>% 
    mutate(counts = n()) %>% 
    ungroup() %>% 
    distinct() %>% 
    arrange(month, day, hour, member)
  
  # make sure that the hold-out set doesn't have new levels
  df11_holdout_agg <- df11_holdout_agg %>% 
    filter(hour %in% unique(df11_train$hour)) %>% 
    filter(day_of_week %in% unique(df11_train$day_of_week))
  
  # make predictions for the hold-out set
  prediction_2011_holdout <- data.frame(predict(lm_2011, newdata = df11_holdout_agg, 
                                     interval = "predict", level = 0.95, 
                                     weights = df11_holdout_agg$counts)) %>% 
    mutate(true_duration = df11_holdout_agg$log_duration)
  
  # find non-coverage rate on hold-out set
  holdout_noncover = nrow(prediction_2011_holdout %>% 
                            filter(true_duration>upr | true_duration<lwr))
  holdout_total = nrow(prediction_2011_holdout)
  holdout_noncover_rate = holdout_noncover/holdout_total
  
  # aggregate on 2010 test data
  df10_agg <- route_df10 %>% 
    select(-c(year, weekend)) %>% 
    group_by(month, day, hour, member) %>% 
    mutate(log_duration = median(log_duration)) %>% 
    mutate(counts = n()) %>% 
    ungroup() %>% 
    distinct() %>% 
    arrange(month, day, hour, member)
  
  # make sure that the 2010 test set doesn't have new levels
  df10_agg <- df10_agg %>% 
    filter(hour %in% unique(df11_train$hour)) %>% 
    filter(day_of_week %in% unique(df11_train$day_of_week))
  
  # make predictions on 2010 test set
  prediction_2010 <- data.frame(predict(lm_2011, newdata = df10_agg, 
                                     interval = "predict", level = 0.95, 
                                     weights = df10_agg$counts)) %>% 
    mutate(true_duration = df10_agg$log_duration) 
  
  # find non-coverage rate on test set
  test_noncover = nrow(prediction_2010 %>% filter(true_duration>upr | true_duration<lwr)) 
  test_total = nrow(prediction_2010)
  test_noncover_rate = test_noncover / test_total
  
  # do binomial test on the 2 non-coverage rates; find p value
  res = binom.test(test_noncover,
               test_total,
               holdout_noncover_rate,
               alternative = "greater")
  p_val = res$p.value
  p_vals = append(p_vals, p_val)
}
```


```{r}
p_vals = p.adjust(p_vals, method = 'fdr')
final2 = data.frame(busy_routes, p_vals)
final2 = final2 %>% filter(p_vals < 0.05)
length(final2$busy_routes)
```

As shown above, when we build a separate model for each route, we identified 66 out of 159 `busy_routes` we considered. 

## 3.2 Discussion

First, the result of this approach (building a separate model for each route) is also subject to the same potential limitation imposed by the change of composition in the unobserved confounders, which has already been discussed in section 2.2.

Now, we can find the intersection of the significant routes detected by these two ways. 


```{r include=FALSE}
final1 = read.csv('single.csv')
```

```{r}
intersect(final2$busy_routes, final1$noncoverage_rates_2010.route)
length(intersect(final2$busy_routes, final1$noncoverage_rates_2010.route))
```

We that the overlap between the two sets of discoveries is roughly 40% of each of them. This indicates that whether to build separate model for each route does affect the result, and which method to use would depend on the assumptions we want to make (i.e. whether different routes should share the same set of coefficients for the covariates). On the other hand, the overlapped routes identified by both methods may suugest that they more likely had undertaken changes between 2010 and 2011. 






