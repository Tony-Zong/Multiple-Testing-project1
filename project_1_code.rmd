---
title: "STAT 27850 Project 1 Code"
author: "Tony Zong, Louisa Lyu, Stanley Zhu"
date: '2023-01-28'
geometry: margin=2cm
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 80), tidy = TRUE)
knitr::opts_chunk$set(echo = TRUE, fig.height = 4, fig.align = 'center')
library(tidyverse)
library(gridExtra)
rm(list=ls())
set.seed(123)
theme_set(theme_bw())
```

# Load Data and Data Cleaning

```{r}
# Remove outliers with IQR range test
outliers <- function(x) {
    q25 <- quantile(x, probs=.25)
    q75 <- quantile(x, probs=.75)
    interval <- q75 - q25
    x > q75 + (interval * 1.5) | x < q25 - (interval * 1.5)
}

# Just remove 5% data on the top end.
outliers2 <- function(x) {
  x > quantile(x, probs=0.95)
}

# Temperature Data
temp_data <- 
  read.table("data/temperature-data.txt", 
           skip = 1, 
           col.names = c('time1', 'time2', 'daily_max', 'daily_min')) %>% 
  mutate(year = as.numeric(substring(time2, 1, 4)), 
         month = as.numeric(substring(time2, 6, 7)), 
         day = as.numeric(substring(time2, 9, 10)), 
         daily_temp = (daily_max + daily_min) / 2)

# Bike-share Data
load("data/bikedata.RData")
colnames(starttime) = c("year", "month", "day", "hour", "minute", "second")
df <- data.frame(log_duration = log(duration), station_start, station_end, 
                starttime, day_of_week, days_since_Jan1_2010, member) %>% 
  # Join with Temperature Data
  left_join(temp_data, by = c('year','month','day')) %>% 
  # Add Weekend/weekday 
  mutate(weekend = day_of_week %in% c("Saturday", "Sunday")) %>% 
  # Add Hour of the Day (with different degree of preciseness)
  mutate(hour_of_day = cut(hour, c(-1, 12, 24))) %>%
  mutate(hour_of_day_2 = cut(hour, c(-1, 6, 12, 18, 24))) %>%
  # Add temperature buckets (with different degree of preciseness)
  mutate(temp = cut(daily_temp, c(20, 40, 60, 80, 100))) %>%
  mutate(temp_2 = cut(daily_temp, c(20, 30, 40, 50, 60, 70, 80, 90, 100))) %>%
  # Assign Id to Route
  group_by(station_start, station_end) %>% 
  mutate(route = paste0(station_start, "-", station_end)) %>% 
  # Filter out routes with less than 500 records
  filter(length(log_duration) >= 500, !outliers(log_duration)) %>% 
  ungroup()

# Drop unnecessary columns
df <- subset(df, select=-c(station_start, station_end, year, month, day, 
                           minute, second, time1, time2, daily_max, daily_min))
```

## Data Distribution

We first check that how much data is left after cleaning - we are left with 603 observations.

```{r}
df %>%
  group_by(route) %>%
  summarize(num_rides = length(log_duration)) %>%
  ggplot(aes(x=num_rides)) +
  geom_histogram()
```

# Permutation test without any control

For each route, we are interested in the question if there is any change in ride duration at any point over the span of 2010-2011. In the language of hypothesis testing, this translates to the hypothesis that ride duration is independent of the days_since_Jan1_2010. Rejecting this hypothesis would mean that ride duration depends on the date - in other words change over time. We observe that the absolute value of correlation between duration and days_since_Jan1_2010 would be relatively small if the hypothesis is true and large otherwise, making it a good candidate statistic for the permutation test. Therefore, we first perform permutation test without any confounder control to gauge how well it works.

``` {r, cache = TRUE}
permutation.test <- function(duration, days_from_start, n=1000) {
  T <- abs(cor(duration, days_from_start))
  distribution <- c()
  for (i in 1:n) {
    distribution[i] <- abs(cor(sample(duration, replace=FALSE), days_from_start))
  }
  p_val <- (1 + sum(distribution >= T)) / (1 + n)
  return (p_val)
}
p_vals <- df %>%
  group_by(route) %>%
  summarize(p_val = permutation.test(log_duration, days_since_Jan1_2010))

# Adjust p_vals for multiple testing
p_vals$p_adjust = p.adjust(p_vals$p_val, method = 'fdr')
```

## P-value Histogram and Graphs

``` {r}
hist(p_vals$p_adjust, xlab="p_value", main="P-value Histogram", breaks=20)
```

We plot the top routes that have the strongest signals and see if they indeed exhibit some kind of change. Each color represents a group.

``` {r}
plot_route_change <- function(df, p_vals, n=2) {
  sorted_pvals <- p_vals[order(p_vals$p_adjust), ]
  par(mfrow=c(round(n/2),2))
  for (i in 1:n) {
    route_df <- filter(df, route == sorted_pvals$route[i]) %>%
      mutate(grouping = paste(member, hour_of_day_2))
    plot(route_df$days_since_Jan1_2010, exp(route_df$log_duration),
         xlab="Days since Jan 1st 2010", ylab="Duration", 
         col=factor(route_df$grouping),
         main=paste("Route ID = ", sorted_pvals$route[i]))
  }
}
plot_route_change(df, p_vals)
```

# Task-Specific Permutation Tests

However, with confounding variables in the play, a simple permutation scheme will not suffice. For example, it is plausible that members generally ride faster than non-members (who may not be frequent riders), and so the correlation between ride duration and date is confounded by the membership status. To account for these many possible confounders, we use a task-specific permutation testing scheme.

Let $X_j$ be the explanatory variables, and $Y$ be the response, which in our case is the ride duration. Suppose $X_0$ is the days_since_Jan1_2010, what we are actually interested in is the following hypothesis test:
$$ H_0: Y \perp \!\!\! \perp X_0 \; | \; X_{-0} \text{ = all other explanatory variables}$$
However, due to limitations in the dataset, it is infeasible to control for all explanatory variables, as we don't have enough data for each possible variable combinations, and we have not collected every possible ambient variables, such as weather, and the riders' ages. Therefore, we opted to control for a limit set of possible confounders. In particular, we control for the following variables:

- membership
- day of the week
- hour of the day
- temperature

During the permutation tests, we only permute data that has the same membership status, is on the same day of the week, and so on. If we let $X = $ days_from_Jan1_2010, $Z = $ (membership status, day, hour, temperature), $Y = $ duration, and $\tilde{X}$ be another days_from_Jan1_2010 data that got permuted, then under the null hypothesis that 
$$ H_0: Y \perp \!\!\! \perp X \; | \; Z $$ 
and an additional assumption that $\mathbb{P}(X \; | \; Z) = \mathbb{P}(\tilde{X} \; | \; Z)$, we have

$$
\begin{aligned}
\mathbb{P}(X,Y,Z) &= \mathbb{P}(X \; | \; Y, Z) \mathbb{P}(Y,Z) \\
&= \mathbb{P}(X \; | \; Z) \mathbb{P}(Y,Z) \qquad \text{Conditional Independence}\\
&= \mathbb{P}(\tilde{X} \; | \; Z) \mathbb{P}(Y,Z) \\
&= \mathbb{P}(\tilde{X}, Y, Z)
\end{aligned}
$$

Therefore, the distribution remains unchanged. This additional assumption that $\mathbb{P}(X \; | \; Z) = \mathbb{P}(\tilde{X} \; | \; Z)$ is reasonable in this case, as we are only saying that a member, or non-member, has the same probability of riding on any day (no further knowledge). As such, we adjust the permutation test scheme to be task specific to account for confounders.

Membership status, the day of the week (weekend or weekday), hour of the day, and temperature might be possible confounders. Adjusting the permutation test scheme to also account for these factors can ensure certain original trends in the data, for example the proportion of weekend rides, remain unchanged. We believe these are intuitive confounders as we would expect rides on Monday or Saturday, at 3am or 3pm, in 80F or 50F to be different.

# Preliminary data distribution exploration

We first plot to compare between the overall duration for member vs non-member, weekend vs weekday, day vs night, and temperature intervals to see if there's a difference in duration in these group categories.

```{r, message=FALSE, warning=FALSE}
plots <- c()
vars <- c("member", "weekend", "hour_of_day_2", "temp")
for (i in 1:length(vars)) {
  plot <- ggplot(data=df, mapping=aes_string(x=vars[i], y="log_duration", fill=vars[i])) +
    stat_boxplot(geom = "errorbar", width = 0.20) + 
    geom_boxplot() + theme(legend.position = "none")
  plots[[i]] <- plot
}
grid.arrange(grobs=plots, ncol = 2)
```

We make the following observations:

- Members overall have lower log_durations than non-members, meaning members spend shorter time riding overall.
- Weekends have slightly higher log_durations compared to the weekdays, suggesting people spend longer time to ride on weekends in general.
- There is little difference in log_duration between different hours, but it seems that durations are a little longer on afternoons.
- There is also little difference in log_duration across different temperatures, but it seems that hotter temperature relates with slightly longer durations.

We will now run the task specific permutation tests.

``` {r, cache = TRUE}
# Task specific Permutation Tests
permutation.task_specific_test <- function(duration, days_from_start, compute_t, grouping, n=1000) {
  t <- compute_t(duration, days_from_start)
  distribution <- c()
  for (i in 1:n) {
    permuted_duration <- 
      ave(duration, grouping, 
          FUN = function(x) if (length(x) == 1) x else sample(x))
    distribution[i] <- compute_t(permuted_duration, days_from_start)
  }
  p_val <- (1 + sum(distribution >= t)) / (1 + n)
  return (p_val)
}

# Absolute value of correlation as the statistic
abscor_t <- function(log_duration, days_from_start) abs(cor(log_duration, days_from_start))

# Control for Membership status, day of the week (2), hour of the day(2), and temperature(4)
# parenthesis represents how many categories there are for each variable
group_controlled_pvals <- df %>%
  group_by(route) %>%
  summarize(p_val = permutation.task_specific_test(log_duration, days_since_Jan1_2010, abscor_t, 
                                                   paste(member, weekend, hour_of_day, temp))) %>%
  # Adjust p_vals for multiple testing
  mutate(p_adjust = p.adjust(p_val, method = 'fdr'))
```

## Task specific P-value Histogram and Graphs

``` {r}
# P-value distribution
hist(group_controlled_pvals$p_adjust, 
     xlab="p_value", main="P-value Histogram", breaks=20)

# Top Routes
plot_route_change(df, group_controlled_pvals, n = 2)
```

# Sanity check of task specific permutation test

To check if our permutation test is working properly, we generate null, non-null, half null and half non-null datasets to check if the permutation test will give us the expected answers.

```{r, cache = TRUE}
# run sanity checks
sanity_check <- function(df) {
  # run the permutation task specific test on the null dataset
  pvalues <- df %>%
    group_by(route) %>%
    summarize(p_val = permutation.task_specific_test(random, days_since_Jan1_2010, abscor_t, 
                                                     paste(member, weekend, hour_of_day, temp), n=100)) %>%
    # Adjust p_vals for multiple testing
    mutate(p_adjust = p.adjust(p_val, method = 'fdr'))

  # Identify routes with p-val < 0.05
  return (nrow(pvalues %>% filter(p_adjust < 0.05)))
}

# null dataset
df_null <- df %>%
  group_by(route) %>%
  mutate(random = rnorm(n(), mean = mean(log_duration), sd = sd(log_duration))) %>%
  ungroup()
print(paste0("Number of significant routes for null dataset: ", sanity_check(df_null)))

# signal dataset
df_nonnull <- df %>%
  group_by(route) %>%
  mutate(random = n():1) %>%
  ungroup()
print(paste0("Number of significant routes for signal dataset: ", sanity_check(df_nonnull)))

# half signal half null dataset
df_halfnull <- df %>%
  group_by(route) %>%
  filter(route %in% group_controlled_pvals$route[1:round(nrow(group_controlled_pvals)/2)]) %>%
  mutate(random = n():1)

df_halfnonnull <- df %>%
  group_by(route) %>%
  filter(route %in% group_controlled_pvals$route[(round(nrow(group_controlled_pvals)/2) + 1):nrow(group_controlled_pvals)]) %>%
  mutate(random = rnorm(n(), mean = mean(log_duration), sd = sd(log_duration)))

df_halfhalf <- rbind(df_halfnull, df_halfnonnull)
print(paste0("Number of significant routes for half/half dataset: ", sanity_check(df_halfhalf)))
```

We see that there is no significant route for the null dataset generated by random normal distribution for each route, with mean being the original mean of the route's log_duration and standard deviation being the original standard deviation of the route's log_duration. Similarly, All the 603 routes are significant for the all signal dataset. The signal dataset is generated by decreasing each route's log_duration as time goes on. 

On the other hand, for the data with half of the routes following random normal distribution and half of the routes following a decreasing trend, we found 302 routes to be significant by the correlation test. By checking with null, signal, and half-null half-signal dataset, we are able to conclude that our task specific permutation test is working properly.

# Finer Bucketing of Data

We then experiment with a finer bucketing of data, where weekdays changed from 2 categories (weekday/weekend) to 7 categories, temperature changed from 20F intervals to 10F intervals, and hour changed from 2 12-hour groups to 4 6-hour groups.

```{r, cache = TRUE}
# FINER control for Membership status, day of the week (7), hour of the day (6), and temperature (8)
# parenthesis represents how many categories are for each variable
group_controlled_pvals2 <- df %>%
  group_by(route) %>%
  summarize(p_val = permutation.task_specific_test(log_duration, days_since_Jan1_2010, abscor_t, 
                                                   paste(member, day_of_week, hour_of_day_2, temp_2), n=100)) %>%
  mutate(p_adjust = p.adjust(p_val, method = 'fdr'))

# Plot P-value histogram and top routes
hist(group_controlled_pvals2$p_adjust, 
     xlab="p_value", main="P-value Histogram", breaks=20)

plot_route_change(df, group_controlled_pvals)
```

We see that the number of significant routes reduces, as we are employing a finer control, which likely leads to less power.

# Exploration of Better statistics to detect sudden changes

As correlation is more suitable in detecting long-term gradual change in data and not as powerful for detecting bumps, we explore other statistics to better identify bumps and changes in the data.

We perform the same task specific permutation test, but change the test statistics to mean or median instead of correlation. We split the data into the "earlier half" and the "later half" based on days_since_Jan_1st_2010. We then compute and compare the mean or median of the two halves. Permutation test will then be performed to see if the difference between the two halves is indeed statistically significant (for each route). 

## Using the mean statistic

```{r, cache = TRUE}
# Task specific permutation tests for mean
mean_t <- function(duration, days_from_start) {
  first_half <- duration[1:round(length(duration)/2)]
  second_half <- duration[(round(length(duration)/2) + 1):length(duration)]
  abs(mean(first_half) - mean(second_half))
}

group_controlled_mean_pvals <- df %>%
  group_by(route) %>%
  summarize(p_val = permutation.task_specific_test(log_duration, days_since_Jan1_2010, mean_t, 
                                                   paste(member, weekend, hour_of_day, temp))) %>%
  mutate(p_adjust = p.adjust(p_val, method = 'fdr'))

hist(group_controlled_mean_pvals$p_adjust, 
     xlab="p_value", main="P-value Histogram", breaks=20)
plot_route_change(df, group_controlled_mean_pvals)
```

## Using the median statistic

```{r, cache = TRUE}
# Task specific permutation tests for median
median_t <- function(duration, days_from_start) {
  first_half <- duration[1:round(length(duration)/2)]
  second_half <- duration[(round(length(duration)/2) + 1):length(duration)]
  median(first_half) - median(second_half)
}

group_controlled_median_pvals <- df %>%
  group_by(route) %>%
  summarize(p_val = permutation.task_specific_test(log_duration, days_since_Jan1_2010, median_t, 
                                                   paste(member, weekend, hour_of_day, temp))) %>%
  mutate(p_adjust = p.adjust(p_val, method = 'fdr'))

hist(group_controlled_median_pvals$p_adjust, 
     xlab="p_value", main="P-value Histogram", breaks=20)
plot_route_change(df, group_controlled_median_pvals, n=2)
```

## Significant routes with all 3 statistics

We check to see how many routes are marked as having a statistically significant change using all 3 statistics.

```{r}
# check the common routes detected by correlation, mean, and median methods
corr_routes <- subset(group_controlled_pvals, p_adjust < 0.05)
mean_routes <- subset(group_controlled_mean_pvals, p_adjust < 0.05)
median_routes <- subset(group_controlled_median_pvals, p_adjust < 0.05)

common_routes <- intersect(mean_routes$route, median_routes$route)
common_routes <- intersect(common_routes, corr_routes$route)
length(common_routes)
head(common_routes, 10)
```

# Significant routes exploration

```{r}
stations = c()
for (route in common_routes) {
  for (st in strsplit(route, "-")) {
    stations = c(stations, st)
  }
}
station_counts <- sort(table(stations), decreasing = TRUE)
head(station_counts, 3)

```

These stations correspond to the Dupont circle (31200 & 31201) and the Columbus circle (31623). However, upon inspecting the news & google map, it is unclear if there has been any change to the actual routes during the period. Both stations are among the top used stations per Capital Bikeshare reports. We conjecture that the gradual decrease over time might be more and more people become more familiar with the locations since the program opens in 2010.

## Discussions and Limitations of the Permutation Test

Our permutation test is effective in identifying long-term changes in trend, and its validity is further improved by using three test statistics (correlation, mean, and median) to find significant routes in common. Nevertheless, there are a few limitations due to the nature of the test statistics and the data itself that should be noted.

Firstly, by plotting out the duration data for the significant routes that the permutation test identified, we noticed that there’s an increase in the amount of data with time. This is probably because the record for Washington D.C.’s bikeshare program started at around 2010 September, thus there’s more people participating in the program as time progresses. This might bias our test statistics due to the larger amount of data points towards the end (in time): with larger sample size, it is more likely that random fluctuations in the data might leads to spurious correlations. 

Secondly, though the permutation test considered membership, day of week, hour of day, and temperature, there are still many other relevant variables that are not considered but worth considering. For example, the age of the rider is likely to influence durations—we would normally expect a 80-year-old to ride slower compared to a 20-year-old. Also, we did not control for weather—we would expect people to take longer riding in rain compared to a sunny or cloudy day. These are not considered due to either limitation in the dataset itself or due to the limited time and resources we have.

Thirdly, our test statistics is not perfect in identifying some abrupt or sudden changes in the data: it captures long-term changes better. We did not find a perfect test statistics that could allow us to detect such sudden changes. Our best conjecture is to chop the data into smaller sections and compare the mean/median between each two consecutive sections. However, due to the limited data for each route, we might not be able to do so while controlling for all the other relevant variables that we should control for (membership, day of week, hour of day, and temperature). 

Fourthly, we noticed that each “route” is specified by a starting station number and an ending station number. However, when looking up on google maps, we noticed that sometimes there exist multiple possible path between two stations. Different path takes slightly different amount of time, but they are all considered to be the same “route” due to the same starting and ending station number. This might bias our result—the correlation might arise due to fluctuations in frequencies people take the shorter vs the longer paths. We tried to improve this problem by removing outliers for each route to exclude some extreme cases (i.e., start from a station, ride around D.C. for 2hrs, and return to a station nearby the starting station), but the result might still be biased by paths that take not so different amount of times. 

## Using correlation only on data from September to December (both 2010 and 2011)

We then re-run the correlation test with only the data from September to December in 2010 and 2011 to compare with the result from our other regression model.

```{r, cache = TRUE}
# filter out only data from september to december in 2010 and 2011
df_sepdec <- df %>%
  filter(member == TRUE) %>%
  filter(between(days_since_Jan1_2010, 243, 364) | between(days_since_Jan1_2010, 608, 729))
# test statistics to compare the median between 2010 sep-dec and 2011 sep-dec
median_t_sepdec <- function(duration, days_from_start) {
  first_half <- duration[1:(which(days_from_start > 608)[1] - 1)]
  second_half <- duration[which(days_from_start > 608)[1]:length(duration)]
  median(first_half) - median(second_half)
}
group_controlled_sepdec_pvals <- df_sepdec %>%
  group_by(route) %>%
  summarize(p_val = permutation.task_specific_test(log_duration, days_since_Jan1_2010, median_t_sepdec, 
                                                   paste(member, weekend, hour_of_day, temp))) %>%
  # Adjust p_vals for multiple testing
  mutate(p_adjust = p.adjust(p_val, method = 'fdr'))
# Identify routes with p-val < 0.05
significant_routes_sepdec_median <- group_controlled_sepdec_pvals %>% filter(p_adjust < 0.05)
# use absolute correlation on the 2010 sep-dec and 2011 sep-dec
group_controlled_sepdec_pvals <- df_sepdec %>%
  group_by(route) %>%
  summarize(p_val = permutation.task_specific_test(log_duration, days_since_Jan1_2010, abscor_t, 
                                                   paste(member, weekend, hour_of_day, temp))) %>%
  # Adjust p_vals for multiple testing
  mutate(p_adjust = p.adjust(p_val, method = 'fdr'))
# Identify routes with p-val < 0.05
significant_routes_sepdec_abscor<- group_controlled_sepdec_pvals %>% filter(p_adjust < 0.05)
```

```{r}
plot_route_change(df_sepdec, group_controlled_sepdec_pvals)
```

We believe the median/mean test statistics is the most relevant or comparable test statistics with the regression test as both treated 2010 and 2011 data separately and compared the two with each other. The median test statistics would be better than mean as it will not be affected by outliers. Therefore, we find the common routes identified by the permutation (median test statistics) with the regression test to see if the two methods give common results.

```{r}
# Find common routes identified by permutation (median) and regression test
regression <- read.csv("single.csv")
intersect(significant_routes_sepdec_median$route, regression$noncoverage_rates_2010.route)
```

We then find common routes identified by permutation (median), permutation (absolute correlation), and regression test to identify routes that are shown to be significantly changed by all three test statistics. Since absolute correlation and median are testing different types of changes, we think these routes are most likely to have some sort of changes as it survived all three tests (that are all testing changes from slightly different approachs).

```{r}
# Find common routes identified by permutation (median) and regression test
intersect(intersect(significant_routes_sepdec_median$route, significant_routes_sepdec_abscor$route), regression$noncoverage_rates_2010.route)
```