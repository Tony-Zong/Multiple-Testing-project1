---
title: "Permutation Test"
author: "Tony Zong, Louisa Lyu, Stanley Zhu"
date: '2023-01-28'
geometry: margin=2cm
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 80), tidy = TRUE)
knitr::opts_chunk$set(echo = TRUE, fig.height = 4, fig.align = 'center')
library(tidyverse)
library(gridExtra)
set.seed(123)
theme_set(theme_bw())

rm(list=ls())
```
# Section I: Introduction to the Permutation Test
This permutation approach finds routes that seem to show change in duration over time, and then permute the duration to see if the change is or is not likely to appear when data is randomly shuffled. For routes that is statistically unlikely to have the actual changes when randomly shuffled, we believe the change is unlikely to be due to random fluctuation in data but indeed an actual change in duration. Thus, these routes will be marked as significant. Because we are testing for hundreds of routes simultaneously, we also used multiple testing correction to control for false discovery rate when computing p values and making inferences. 

## 1.1 Outline of the steps taken
**Step 0:** Data cleaning, filter out only routes with sufficient number of records (>500) to perform the permutation test.

**Step 1:** Run the permutation test on each route without controlling for any covariate to guage its efficiency in identifying routes.

**Step 2:** Run the task specific permutation test, which is the permutation test with control for covariate, on the routes. With control, only data within the same group category get shuffled. For example, morning rides will only be shuffled with other morning rides, and member rides will only be shuffled with other members' rides. This approach preserves original trends and structures in the data so that original trends will be preserved. 

**Step 3:** Evaluate the task specific permutation test's reliability by simulations. We constructed three fake datasets: completely null distributions for all routes, strictly decreasing distribution for all routes, and half null half decreasing distributions for all routes. We then run our task specific permutation test to see if it correctly identified the non-null routes.

**Step 4:** Explore possible improvements on the task specific permutation test. Here, two approaches are attempted:

Firstly, we tried to use finer bucketing of data on routes with sufficiently large amount of data (>1000) to see it's effectiveness. For these popular routes, we divided covariate like temperature, day of week, and hour of day more meticulously. For example, we split temperature into 10F intervals, compared to before splitting them into 20F intervals. 

Secondly, we explored other test statistics, for example by dividing the data in middle for each route and calculate the mean and median differences between the two halves. These method might be able to better identify sudden changes compared to absolute correlation test, which is more effectively at finding long-term changes.

**Step 5:** Find common significant routes identified by different test statistics in permutation test. Do research to explore the routes on map and see if our results actually correspond to real-world constructions, or explore possible reasons for our significant results.

## 1.2 Load Data and Data Cleaning

```{r}
# Remove outliers with IQR range test
outliers <- function(x) {
    q25 <- quantile(x, probs=.25)
    q75 <- quantile(x, probs=.75)
    interval <- q75 - q25
    x > q75 + (interval * 1.5) | x < q25 - (interval * 1.5)
}

# Just remove 5% data on the top end.
outliers2 <- function(x) {
  x > quantile(x, probs=0.95)
}

# Temperature Data
temp_data <- 
  read.table("data/temperature-data.txt", 
           skip = 1, 
           col.names = c('time1', 'time2', 'daily_max', 'daily_min')) %>% 
  mutate(year = as.numeric(substring(time2, 1, 4)), 
         month = as.numeric(substring(time2, 6, 7)), 
         day = as.numeric(substring(time2, 9, 10)), 
         daily_temp = (daily_max + daily_min) / 2)

# Bike-share Data
load("data/bikedata.RData")
colnames(starttime) = c("year", "month", "day", "hour", "minute", "second")
df <- data.frame(log_duration = log(duration), station_start, station_end, 
                starttime, day_of_week, days_since_Jan1_2010, member) %>% 
  # Join with Temperature Data
  left_join(temp_data, by = c('year','month','day')) %>% 
  # Add Weekend/weekday 
  mutate(weekend = day_of_week %in% c("Saturday", "Sunday")) %>% 
  # Add Hour of the Day (with different degree of preciseness)
  mutate(hour_of_day = cut(hour, c(-1, 12, 24))) %>%
  mutate(hour_of_day_2 = cut(hour, c(-1, 6, 12, 18, 24))) %>%
  # Add temperature buckets (with different degree of preciseness)
  mutate(temp = cut(daily_temp, c(20, 40, 60, 80, 100))) %>%
  mutate(temp_2 = cut(daily_temp, c(20, 30, 40, 50, 60, 70, 80, 90, 100))) %>%
  # Assign Id to Route
  group_by(station_start, station_end) %>% 
  mutate(route = paste0(station_start, "-", station_end)) %>% 
  # Filter out routes with less than 500 records
  filter(length(log_duration) >= 500, !outliers(log_duration)) %>% 
  ungroup()

# Drop unnecessary columns
df <- subset(df, select=-c(station_start, station_end, month, day, 
                           minute, second, time1, time2, daily_max, daily_min))
```

## 1.3 Data Distribution

We first check that how much data is left after cleaning - we are left with 603 observations.

```{r}
df %>%
  group_by(route) %>%
  summarize(num_rides = length(log_duration)) %>%
  ggplot(aes(x=num_rides)) +
  geom_histogram()
```
# Section II: Permutation test without Any Control

## 2.1 Permutation test code
For each route, we are interested in the question if there is any change in ride duration at any point over the span of 2010-2011. In the language of hypothesis testing, this translates to the hypothesis that ride duration is independent of the days_since_Jan1_2010. Rejecting this hypothesis would mean that ride duration depends on the date - in other words change over time. We observe that the absolute value of correlation between duration and days_since_Jan1_2010 would be relatively small if the hypothesis is true and large otherwise, making it a good candidate statistic for the permutation test. Therefore, we first perform permutation test without any confounder control to gauge how well it works.

``` {r, cache = TRUE}
permutation.test <- function(duration, days_from_start, n=1000) {
  T <- abs(cor(duration, days_from_start))
  distribution <- c()
  for (i in 1:n) {
    distribution[i] <- abs(cor(sample(duration, replace=FALSE), days_from_start))
  }
  p_val <- (1 + sum(distribution >= T)) / (1 + n)
  return (p_val)
}
p_vals <- df %>%
  group_by(route) %>%
  summarize(p_val = permutation.test(log_duration, days_since_Jan1_2010))

# Adjust p_vals for multiple testing
p_vals$p_adjust = p.adjust(p_vals$p_val, method = 'fdr')
```

## 2.2 P-value Histogram and Graphs

``` {r}
hist(p_vals$p_adjust, xlab="p_value", main="P-value Histogram", breaks=20)
```

We plot the top routes that have the strongest signals and see if they indeed exhibit some kind of change. Each color represents a group.

``` {r}
plot_route_change <- function(df, p_vals, n=2) {
  sorted_pvals <- p_vals[order(p_vals$p_adjust), ]
  par(mfrow=c(round(n/2),2))
  for (i in 1:n) {
    route_df <- filter(df, route == sorted_pvals$route[i]) %>%
      mutate(grouping = paste(member, hour_of_day_2))
    plot(route_df$days_since_Jan1_2010, exp(route_df$log_duration),
         xlab="Days since Jan 1st 2010", ylab="Duration", 
         col=factor(route_df$grouping),
         main=paste("Route ID = ", sorted_pvals$route[i]))
  }
}
plot_route_change(df, p_vals)
```

# Section III: Task-Specific Permutation Tests

However, with confounding variables in the play, a simple permutation scheme will not suffice. For example, it is plausible that members generally ride faster than non-members (who may not be frequent riders), and so the correlation between ride duration and date is confounded by the membership status. To account for these many possible confounders, we use a task-specific permutation testing scheme.

Let $X_j$ be the explanatory variables, and $Y$ be the response, which in our case is the ride duration. Suppose $X_0$ is the days_since_Jan1_2010, what we are actually interested in is the following hypothesis test:
$$ H_0: Y \perp \!\!\! \perp X_0 \; | \; X_{-0} \text{ = all other explanatory variables}$$
However, due to limitations in the dataset, it is infeasible to control for all explanatory variables, as we don't have enough data for each possible variable combinations, and we have not collected every possible ambient variables, such as weather, and the riders' ages. Therefore, we opted to control for a limit set of possible confounders. In particular, we control for the following variables:

- membership
- day of the week
- hour of the day
- temperature

During the permutation tests, we only permute data that has the same membership status, is on the same day of the week, and so on. If we let $X = $ days_from_Jan1_2010, $Z = $ (membership status, day, hour, temperature), $Y = $ duration, and $\tilde{X}$ be another days_from_Jan1_2010 data that got permuted, then under the null hypothesis that 
$$ H_0: Y \perp \!\!\! \perp X \; | \; Z $$ 
and an additional assumption that $\mathbb{P}(X \; | \; Z) = \mathbb{P}(\tilde{X} \; | \; Z)$, we have

$$
\begin{aligned}
\mathbb{P}(X,Y,Z) &= \mathbb{P}(X \; | \; Y, Z) \mathbb{P}(Y,Z) \\
&= \mathbb{P}(X \; | \; Z) \mathbb{P}(Y,Z) \qquad \text{Conditional Independence}\\
&= \mathbb{P}(\tilde{X} \; | \; Z) \mathbb{P}(Y,Z) \\
&= \mathbb{P}(\tilde{X}, Y, Z)
\end{aligned}
$$

Therefore, the distribution remains unchanged. This additional assumption that $\mathbb{P}(X \; | \; Z) = \mathbb{P}(\tilde{X} \; | \; Z)$ is reasonable in this case, as we are only saying that a member, or non-member, has the same probability of riding on any day (no further knowledge). As such, we adjust the permutation test scheme to be task specific to account for confounders.

Membership status, the day of the week (weekend or weekday), hour of the day, and temperature might be possible confounders. Adjusting the permutation test scheme to also account for these factors can ensure certain original trends in the data, for example the proportion of weekend rides, remain unchanged. We believe these are intuitive confounders as we would expect rides on Monday or Saturday, at 3am or 3pm, in 80F or 50F to be different.

## 3.1 Preliminary data distribution exploration

We first plot to compare between the overall duration for member vs non-member, weekend vs weekday, day vs night, and temperature intervals to see if there's a difference in duration in these group categories.

```{r, message=FALSE, warning=FALSE}
plots <- c()
vars <- c("member", "weekend", "hour_of_day_2", "temp")
for (i in 1:length(vars)) {
  plot <- ggplot(data=df, mapping=aes_string(x=vars[i], y="log_duration", fill=vars[i])) +
    stat_boxplot(geom = "errorbar", width = 0.20) + 
    geom_boxplot() + theme(legend.position = "none")
  plots[[i]] <- plot
}
grid.arrange(grobs=plots, ncol = 2)
```

We make the following observations:

- Members overall have lower log_durations than non-members, meaning members spend shorter time riding overall.
- Weekends have slightly higher log_durations compared to the weekdays, suggesting people spend longer time to ride on weekends in general.
- There is little difference in log_duration between different hours, but it seems that durations are a little longer on afternoons.
- There is also little difference in log_duration across different temperatures, but it seems that hotter temperature relates with slightly longer durations.

We will now run the task specific permutation tests.

## 3.2 Task specific permutation tests code
``` {r, cache = TRUE}
# Task specific Permutation Tests
permutation.task_specific_test <- function(duration, days_from_start, compute_t, grouping, n=1000) {
  t <- compute_t(duration, days_from_start)
  distribution <- c()
  for (i in 1:n) {
    permuted_duration <- 
      ave(duration, grouping, 
          FUN = function(x) if (length(x) == 1) x else sample(x))
    distribution[i] <- compute_t(permuted_duration, days_from_start)
  }
  p_val <- (1 + sum(distribution >= t)) / (1 + n)
  return (p_val)
}

# Absolute value of correlation as the statistic
abscor_t <- function(log_duration, days_from_start) abs(cor(log_duration, days_from_start))

# Control for Membership status, day of the week (2), hour of the day(2), and temperature(4)
# parenthesis represents how many categories there are for each variable
group_controlled_pvals <- df %>%
  group_by(route) %>%
  summarize(p_val = permutation.task_specific_test(log_duration, days_since_Jan1_2010, abscor_t, 
                                                   paste(member, weekend, hour_of_day, temp))) %>%
  # Adjust p_vals for multiple testing
  mutate(p_adjust = p.adjust(p_val, method = 'fdr'))
```

## 3.3 Task specific P-value Histogram and Graphs

``` {r}
# P-value distribution
hist(group_controlled_pvals$p_adjust, 
     xlab="p_value", main="P-value Histogram", breaks=20)

# Top Routes
plot_route_change(df, group_controlled_pvals, n = 2)
```

## 3.4 Sanity check of task specific permutation test

To check if our permutation test is working properly, we generate null, non-null, half null and half non-null datasets to check if the permutation test will give us the expected answers.

```{r, cache = TRUE}
# run sanity checks
sanity_check <- function(df) {
  # run the permutation task specific test on the null dataset
  pvalues <- df %>%
    group_by(route) %>%
    summarize(p_val = permutation.task_specific_test(random, days_since_Jan1_2010, abscor_t, 
                                                     paste(member, weekend, hour_of_day, temp), n=100)) %>%
    # Adjust p_vals for multiple testing
    mutate(p_adjust = p.adjust(p_val, method = 'fdr'))

  # Identify routes with p-val < 0.05
  return (nrow(pvalues %>% filter(p_adjust < 0.05)))
}

# null dataset
df_null <- df %>%
  group_by(route) %>%
  mutate(random = rnorm(n(), mean = mean(log_duration), sd = sd(log_duration))) %>%
  ungroup()
print(paste0("Number of significant routes for null dataset: ", sanity_check(df_null)))

# signal dataset
df_nonnull <- df %>%
  group_by(route) %>%
  mutate(random = n():1) %>%
  ungroup()
print(paste0("Number of significant routes for signal dataset: ", sanity_check(df_nonnull)))

# half signal half null dataset
df_halfnull <- df %>%
  group_by(route) %>%
  filter(route %in% group_controlled_pvals$route[1:round(nrow(group_controlled_pvals)/2)]) %>%
  mutate(random = n():1)

df_halfnonnull <- df %>%
  group_by(route) %>%
  filter(route %in% group_controlled_pvals$route[(round(nrow(group_controlled_pvals)/2) + 1):nrow(group_controlled_pvals)]) %>%
  mutate(random = rnorm(n(), mean = mean(log_duration), sd = sd(log_duration)))

df_halfhalf <- rbind(df_halfnull, df_halfnonnull)
print(paste0("Number of significant routes for half/half dataset: ", sanity_check(df_halfhalf)))
```

We see that there is no significant route for the null dataset generated by random normal distribution for each route, with mean being the original mean of the route's log_duration and standard deviation being the original standard deviation of the route's log_duration. Similarly, All the 603 routes are significant for the all signal dataset. The signal dataset is generated by decreasing each route's log_duration as time goes on. 

On the other hand, for the data with half of the routes following random normal distribution and half of the routes following a decreasing trend, we found 302 routes to be significant by the correlation test. By checking with null, signal, and half-null half-signal dataset, we are able to conclude that our task specific permutation test is working properly.

## 3.5 Finer Bucketing of Data with task specific permutation test

We then experiment with a finer bucketing of data, where weekdays changed from 2 categories (weekday/weekend) to 7 categories, temperature changed from 20F intervals to 10F intervals, and hour changed from 2 12-hour groups to 4 6-hour groups.

```{r, cache = TRUE}
# FINER control for Membership status, day of the week (7), hour of the day (6), and temperature (8)
# parenthesis represents how many categories are for each variable
group_controlled_pvals2 <- df %>%
  group_by(route) %>%
  summarize(p_val = permutation.task_specific_test(log_duration, days_since_Jan1_2010, abscor_t, 
                                                   paste(member, day_of_week, hour_of_day_2, temp_2), n=100)) %>%
  mutate(p_adjust = p.adjust(p_val, method = 'fdr'))

# Plot P-value histogram and top routes
hist(group_controlled_pvals2$p_adjust, 
     xlab="p_value", main="P-value Histogram", breaks=20)

plot_route_change(df, group_controlled_pvals)
```

We see that the number of significant routes reduces, as we are employing a finer control, which likely leads to less power.

# Section IV: Exploration of Better Statistics to Detect Sudden Changes

As correlation is more suitable in detecting long-term gradual change in data and not as powerful for detecting bumps, we explore other statistics to better identify bumps and changes in the data.

We perform the same task specific permutation test, but change the test statistics to mean or median instead of correlation. We split the data into the "earlier half" and the "later half" based on days_since_Jan_1st_2010. We then compute and compare the mean or median of the two halves. Permutation test will then be performed to see if the difference between the two halves is indeed statistically significant (for each route). 

## 4.1 Using the mean statistic

```{r, cache = TRUE}
# Task specific permutation tests for mean
mean_t <- function(duration, days_from_start) {
  first_half <- duration[1:round(length(duration)/2)]
  second_half <- duration[(round(length(duration)/2) + 1):length(duration)]
  abs(mean(first_half) - mean(second_half))
}

group_controlled_mean_pvals <- df %>%
  group_by(route) %>%
  summarize(p_val = permutation.task_specific_test(log_duration, days_since_Jan1_2010, mean_t, 
                                                   paste(member, weekend, hour_of_day, temp))) %>%
  mutate(p_adjust = p.adjust(p_val, method = 'fdr'))

hist(group_controlled_mean_pvals$p_adjust, 
     xlab="p_value", main="P-value Histogram", breaks=20)
```
```{r}
plot_route_change(df, group_controlled_mean_pvals)
```

```{r}
print(paste0("Number of significant routes using mean statistics: ", nrow(group_controlled_mean_pvals %>% filter(p_adjust < 0.05))))
```

## 4.2 Using the median statistic

```{r, cache = TRUE}
# Task specific permutation tests for median
median_t <- function(duration, days_from_start) {
  first_half <- duration[1:round(length(duration)/2)]
  second_half <- duration[(round(length(duration)/2) + 1):length(duration)]
  median(first_half) - median(second_half)
}

group_controlled_median_pvals <- df %>%
  group_by(route) %>%
  summarize(p_val = permutation.task_specific_test(log_duration, days_since_Jan1_2010, median_t, 
                                                   paste(member, weekend, hour_of_day, temp))) %>%
  mutate(p_adjust = p.adjust(p_val, method = 'fdr'))

hist(group_controlled_median_pvals$p_adjust, 
     xlab="p_value", main="P-value Histogram", breaks=20)
```

```{r}
plot_route_change(df, group_controlled_median_pvals, n=2)
```

```{r}
print(paste0("Number of significant routes using median statistics: ", nrow(group_controlled_median_pvals %>% filter(p_adjust < 0.05))))
```

## 4.3 Significant routes with all 3 statistics

We check to see how many routes are marked as having a statistically significant change using all 3 statistics (absolute correlation, mean, and median) with the task specific permutation test.

```{r}
# check the common routes detected by correlation, mean, and median methods
corr_routes <- subset(group_controlled_pvals, p_adjust < 0.05)
mean_routes <- subset(group_controlled_mean_pvals, p_adjust < 0.05)
median_routes <- subset(group_controlled_median_pvals, p_adjust < 0.05)

common_routes <- intersect(intersect(mean_routes$route, median_routes$route), corr_routes$route)
length(common_routes)
head(common_routes, 10)
```

## 4.4 Significant routes exploration

```{r}
stations = c()
for (route in common_routes) {
  for (st in strsplit(route, "-")) {
    stations = c(stations, st)
  }
}
station_counts <- sort(table(stations), decreasing = TRUE)
head(station_counts, 3)
```

These stations correspond to the Dupont circle (31200 & 31201) and the Columbus circle (31623). However, upon inspecting the news & google map, it is unclear if there has been any change to the actual routes during the period. Both stations are among the top used stations per Capital Bikeshare reports. We conjecture that the gradual decrease over time might be more and more people become more familiar with the locations since the program opens in 2010.